---
output:
  md_document:
    variant: markdown_github
---
[![Travis-CI Build Status](https://travis-ci.org/thierrygosselin/stackr.svg?branch=master)](https://travis-ci.org/thierrygosselin/stackr)
[![AppVeyor Build Status](https://ci.appveyor.com/api/projects/status/github/thierrygosselin/stackr?branch=master&svg=true)](https://ci.appveyor.com/project/thierrygosselin/stackr)
[![CRAN_Status_Badge](http://www.r-pkg.org/badges/version/stackr)](http://cran.r-project.org/package=stackr)
[![Project Status: Active – The project has reached a stable, usable state and is being actively developed.](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)
[![DOI](https://zenodo.org/badge/14548/thierrygosselin/stackr.svg)](https://zenodo.org/badge/latestdoi/14548/thierrygosselin/stackr)

```{r, echo = FALSE}
description <- readLines("DESCRIPTION")
rvers <- stringr::str_match(grep("R \\(", description, value = TRUE), "[0-9]{1,4}\\.[0-9]{1,4}\\.[0-9]{1,4}")[1,1]
```
```{r, echo = FALSE}
description <- readLines("DESCRIPTION")
version <- gsub(" ", "", gsub("Version:", "", grep("Version:", description, value = TRUE)))
```
[![packageversion](https://img.shields.io/badge/Package%20version-`r version`-orange.svg)](commits/master)
[![Last-changedate](https://img.shields.io/badge/last%20change-`r gsub('-', '--', Sys.Date())`-brightgreen.svg)](/commits/master)

---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```


# stackr: an R package for the analysis of GBS/RADseq data

This is the development page of the **stackr**, 
if you want to help, see [contributions section](https://github.com/thierrygosselin/stackr#contributions)

## Use stackr to: import, explore, manipulate, visualize, filter, impute and export your GBS/RADseq data

Most genomic analysis look for patterns and trends with various statistics. 
Bias, noise and outliers can have bounded influence on estimators and interfere
with polymorphism discovery. Avoid bad data exploration and control the impact
of filters on your downstream genetic analysis.
    

| Caracteristics | Description |
|:-------------------|:--------------------------------------------------------|
| **Import** | Various supported genomic file formats:<br> [VCF](https://samtools.github.io/hts-specs/) (Danecek et al., 2011), [PLINK tped/tfam](http://pngu.mgh.harvard.edu/~purcell/plink/data.shtml#tr) (Purcell et al., 2007), [adegenet genind and genlight](https://github.com/thibautjombart/adegenet) (Jombart et al., 2010; Jombart and Ahmed, 2011), [strataG gtypes](https://github.com/EricArcher/strataG), [Genepop](http://genepop.curtin.edu.au) (Raymond and Rousset, 1995; Rousset, 2008), [STACKS haplotype file](http://catchenlab.life.illinois.edu/stacks/) (Catchen et al., 2011, 2013), dataframes of genotypes in wide or long/tidy format |
| **Output** |Export back in the 8 formats mentionned above, with 5 additionnal formats for output: **betadiv** (Lamy, 2015), **dadi** (Gutenkunst et al., 2009), **structure** (Pritchard et al., 2000), **Arlequin** (Excoffier et al. 2005) and [hierfstat](https://github.com/jgx65/hierfstat) (Goudet, 2005)|
|**Conversion functions**| `tidy_genomic_format` and `genomic_converter` are conversion functions integrated with important filters, blacklist and whitelist.|
|**Explore** and **filter**| alleles, genotypes, markers, individuals and populations can be filtered and/or selected in several ways.<br><br>`missing_visualization:` visualize patterns of missing data<br>`filter_coverage`: read depth (coverage) of alleles and genotypes<br>`filter_genotype_likelihood`: genotype likelihood<br>`filter_individual` and `filter_population`: genotyped individuals and populations<br>`filter_maf`: minor allele frequency (local and global MAF)<br>`filter_het`observed heterozygosity (Het obs), `filter_fis`: inbreeding coefficient (Fis) and `filter_hw`: Hardy-Weinberg Equilibrium expectations (HWE)<br>`find_duplicate_genome`:find duplicate individuals<br>`filter_het`: as an option to detect potentially mixed samples|
|**Imputations**|**Map-independent** imputations of missing genotypes.<br>Using **Random Forest** or the most frequent category.<br> Imputations can be conducted **overall samples** or **by populations**.<br><br>Imputations are integrated in several functions and in a separate module: `stackr_imputations_module`|
|**[ggplot2](http://ggplot2.org)-based plotting**|View assignment results and create publication-ready figures|
|**Parallel**|Codes designed and optimized for fast computations running imputations, iterations, etc. in parallel|

## Installation
To try out the dev version of **stackr**, copy/paste the code below:

```r
if (!require("devtools")) install.packages("devtools") # to install
devtools::install_github("thierrygosselin/stackr", build_vignettes = TRUE)  # to install WITH vignettes
library(stackr) # to load
```

## Prerequisite - Suggestions - Troubleshooting
  * **Parallel computing**: Follow the steps in this [vignette](https://github.com/thierrygosselin/stackr/blob/master/vignettes/vignette_imputations_parallel.Rmd) 
  to install an OpenMP enabled [randomForestSRC](http://www.ccs.miami.edu/~hishwaran/rfsrc.html)
 package to do imputations in parallel.
  * **Installation problem:** see this
  [vignette](https://github.com/thierrygosselin/stackr/blob/master/vignettes/vignette_installation_problems.Rmd)
  * **Windows users**:  1. Install [Rtools](https://cran.r-project.org/bin/windows/Rtools/). 2. To have *stackr* run in parallel, use [parallelsugar](https://github.com/nathanvan/parallelsugar).
  Easy to install and use ([instructions](https://github.com/nathanvan/parallelsugar#installation)).
  * For a better experience in **stackr** and in R in general, I recommend using [RStudio](https://www.rstudio.com/products/rstudio/download/). 
  The R GUI is unstable with functions using parallel ([more info](https://stat.ethz.ch/R-manual/R-devel/library/parallel/html/mclapply.html)). 


Below, the combination of packages and how I install/load them :

```r
if (!require("pacman")) install.packages("pacman")
pacman::p_load(devtools, tidyverse, data.table, parallel, lazyeval, randomForestSRC)
devtools::install_github("thierrygosselin/stackr", build_vignettes = TRUE)
library("stackr")
```

## Vignettes, R Notebooks and examples

**Vignettes (in development, check periodically for updates):**

* [installation problems](https://github.com/thierrygosselin/stackr/blob/master/vignettes/vignette_installation_problems.Rmd)
* [parallel computing during imputations](https://github.com/thierrygosselin/stackr/blob/master/vignettes/vignette_imputations_parallel.Rmd) 
* [vcf2dadi](https://github.com/thierrygosselin/stackr/blob/master/vignettes/vignette_vcf2dadi.Rmd)
* [haplo2genind](https://github.com/thierrygosselin/stackr/blob/master/vignettes/vignette_haplo2genind.Rmd)

Vignettes can also be accessed inside R with:
```r
browseVignettes("stackr") # To browse vignettes
vignette("vignette_vcf2dadi") # To open specific vignette
```

**R Notebooks:**

* Missing data visualization and analysis [(html vignette)](https://www.dropbox.com/s/4zf032g6yjatj0a/vignette_missing_data_analysis.nb.html?dl=0) and [(Rmd)](https://www.dropbox.com/s/5fxw2h9w1l1j391/vignette_missing_data_analysis.Rmd?dl=0)


## Citation:
To get the citation, inside R:
```r
citation("stackr")
```

## New features
Change log, version, new features and bug history now lives in the [NEWS.md file](https://github.com/thierrygosselin/stackr/blob/master/NEWS.md)


**v.0.4.5**

* temporary fix to `tidy_genomic_data` to read unconventional Tassel VCF

* new function `ibdg_fh` computes the FH measure that was previously
computed in `summary_haplotypes`.
It now works with biallelic and multiallelic data.

    The FH measure is based on the excess in the observed number of homozygous
genotypes within an individual relative to the mean number of homozygous
genotypes expected under random mating (see function for details). The `IBDg` in
the name is because the measure is a proxy of the realized proportion of the genome
that is identical by descent by reference to the current population 
under hypothetical random mating.

* `missing_visualization` now computes the FH measure and look for correlation
with average missingness per individual.
* `tidy_stacks_haplotypes_vcf` is now deprecated in favor of using `tidy_genomic_data`
that will import haplotypic vcf files.

**v.0.4.4**

* several updates to make functions faster.
* `stackr_imputations_module` no longer imputes globally after imputations
by populations. Instead, use `common.markers` or not to test impacts.
*  bug fix with `ref_alt_alleles` that was not working properly inside
the imputation module.
* `snp_ld` is not a separate module available for users. Check documentation.
* `missing_visualization` now show the proportion of variance with plot axis text.

For previous news:
[NEWS.md file](https://github.com/thierrygosselin/stackr/blob/master/NEWS.md)

## Roadmap of future developments:

* Until publication **stackr** will change rapidly (see contributions below for bug reports).
* Updated filters: more efficient, interactive and visualization included: *in progress*
* Workflow tutorial that links functions and points to specific vignettes to further explore some problems: *in progress*
* Integration of several functions with [STACKS](http://catchenlab.life.illinois.edu/stacks/) and [DArT](http://www.diversityarrays.com) database.
* Use Shiny and ggvis when subplots or facets becomes available...
* Suggestions ?


## Contributions:

This package has been developed in the open, and it wouldn’t be nearly as good without your contributions. There are a number of ways you can help me make this package even better:

* If you don’t understand something, please let me know. 
* Your feedback on what is confusing or hard to understand is valuable. 
* If you spot a typo, feel free to edit the underlying page and send a pull request.

New to pull request on github ? The process is very easy:

* Click the edit this page on the sidebar.
* Make the changes using github’s in-page editor and save.
* Submit a pull request and include a brief description of your changes. 
* “Fixing typos” is perfectly adequate.


## GBS workflow
The **stackr** package fits currently at the end of the GBS workflow. Below, a flow chart using [STACKS](http://catchenlab.life.illinois.edu/stacks/) and other software.
![](vignettes/GBS_workflow.png)

## stackr workflow 
Currently under construction. Come back soon!

**Table 1: Quality control and filtering RAD/GBS data**

| Parameters | Libraries & Seq.Lanes | Alleles | Genotypes | Individuals | Markers | Sampling sites | Populations | Globally |
|:----|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
| Quality |x| | |x| | | | |
| Assembly and genotyping |x| | | | | | | |
| Outliers | |x|x|x|x| | | |
| Missingness |x|x|x|x|x|x|x|x|
| Coverage | |x|x| |x| | | |
| Genotype Likelihood | | |x| | | | | |
| Prop. Genotyped | | | |x|x|x|x|x|
| HET & FIS & HWE | | | |x|x| |x| |
| MAF | | | | |x|x|x|x|
| Missingness |x|x|x|x|x|x|x|x|


**Step 1 Quality** Ask yourself these questions: 

* DNA quality, libraries quality, sequencing lanes quality ? 
* Please stop thinking in terms of quantity (e.g. millions of reads returned), and start thinking about actual quality of your new data.
* Use quality metrics inside available software (e.g. fastqc)

**Step 2 *de novo* assembly and genotyping** 

* This is conducted outside stackr
* Integrated software pipelines include: [STACKS](http://catchenlab.life.illinois.edu/stacks/), [pyRAD](http://dereneaton.com/software/), [dDocent](https://ddocent.wordpress.com), [AftrRAD](http://u.osu.edu/sovic.1/downloads/). If you want to develop your own pipeline, 
there are a multitude of approaches, good luck. 

**Step 3 Outliers**

* Remove replicates (I hope you have some).
* Remove *de novo* assembly artifact, by creating blacklist of genotypes or whitelist of markers:
    * individuals with more than 2 alleles (use `summary_haplotypes`)
    * outlier markers with extreme number of SNP/read or haplotype (use `filter_snp_number`)
* Remove potential duplicated samples that went off your radar, try `find_duplicate_genome`.
* Highlight outliers individual's heterozygosity that might represent mixed samples with `filter_individual_het`.
* The metric you're using: a *de novo* artefact or a reliable signal of biological polymorphism?
* Should the statistic you are interested in be consistent throughout the read ?
* Will you consider haplotype or snp level statistics?
* The consistensies of SNPs statistics among haplotype can be throughly tested by using `snp.ld` argument in several stackr functions.
* Any other outliers with different individual's or markers metrics (reads/sample, etc) ?

**Step 4 Pattern of missingness**

* Use `missing_visualization` with/without your new blacklists (e.g. of genotypes, individuals) and with/without whitelist of markers to examine patterns of missingness in you dataset before more extensive filtering (there is a vignette for this step)
* The trick here is to use the `strata` argument to find patterns associated with different variables of your study (lanes, chips, sequencers, populations, sample sites, reads/samples, etc).
* Do you see a trend between your missing pattern and reads/samples ? Heterozygosity?
* Do you need more sequencing? Do you have to re-run some lanes? 

**Step 5-6 Coverage and Genotype Likelihood**

* Coverage is an individual metric. With most software you'll find allele and genotype coverage info.
* Genotype likelihood is usually a metric based on coverage of the different genotypes found in all of your data.
* Good allele coverage is required for reliable genotypes.
* Reliable genotypes is required for reliable downstream summary statistics.
* Explore filtering options in `filter_coverage` and `filter_genotype_likelihood`.

**Step 7 Prop. Genotyped**

* Do you have enough individuals in each sampling sites (`filter_individual`) 
and enough putative populations (`filter_population`) for each markers ?
* Use blacklist of individuals with different thresholds.
* Keep different whitelist of markers.
* Use `common.markers` argument inside most of stackr functions to test the impact of vetting loci based on shared markers.
* Use imputation methods provided by stackr (inside `tidy_genomic_data` or `genomic_converter`, as a separate module: `stackr_imputations_module`) to assess the impact of lowering or increasing threshold that impact missing data.

**Step 8 HET, Fis, HWE**

* Overall and/or per populations hwe, heterozygosity and Fis statistics can highlight: 
*de novo* assembly problems (oversplitting/undermerging), genotyping problems or
biological problems.
* These filters allows to test rapidly if departure from realistic expectations
are a problem for downstream analysis ?
* Choose your threshold wisely and test impact on pipeline.
* Use `filter_het`, `filter_fis`, `filter_hwe` and look again 
at the individual's heterozygosity (`filter_individual_het`) for outliers.

**Step 9 MAF**

* Remove artifactual and uninformative markers.
* Use MAF arguments inside several of stackr functions to tailor MAF to your analysis tolerance to minor allelel frequencies.
* There is also a separate filter in stackr: `filter_maf`

**Step 10 Pattern of missingness, again**

* Use `missing_visualization` with your new blacklists (e.g. of genotypes, individuals) and with your whitelist of markers to examine patterns of missingness in your dataset after filtering (there is a vignette for this step)
* The trick here is to use the `strata` argument to find patterns associated with different variables of your study (lanes, chips, sequencers, populations, sample sites, reads/samples, etc).
* Do you see a trend between your missing pattern and reads/samples ? Heterozygosity?
