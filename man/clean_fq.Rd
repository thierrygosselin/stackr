% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/clean_fq.R
\name{clean_fq}
\alias{clean_fq}
\title{Removes the noise of an individual fastq file}
\usage{
clean_fq(
  fq.files,
  paired.end = FALSE,
  min.coverage.threshold = 2L,
  max.coverage.threshold = "high.coverage.unique.reads",
  remove.unique.reads = TRUE,
  write.blacklist = TRUE,
  write.blacklist.fasta = TRUE,
  compress = FALSE,
  output = "08_stacks_results/03_cleaned_fq",
  parallel.core = parallel::detectCores() - 1
)
}
\arguments{
\item{fq.files}{(character, path). The path to the individual fastq file to check.
Default: \code{fq.files = "my-sample.fq.gz"}.}

\item{paired.end}{(logical) Are the files paired-end.
Default: \code{paired.end = FALSE}.}

\item{min.coverage.threshold}{(integer). Minimum coverage threshold.
The function will remove distinct reads with coverage <= to the threshold.
To turn off, \code{min.coverage.threshold = NULL or 0L}.
Default: \code{min.coverage.threshold = 2L}.}

\item{max.coverage.threshold}{(integer, character). Maximum coverage threshold.
The function will remove distinct reads with coverage >= than this threshold.
To turn off, \code{max.coverage.threshold = NULL}.
The default, use the starting depth where high coverage unique reads are observed.
Default: \code{max.coverage.threshold = "high.coverage.unique.reads"}.}

\item{remove.unique.reads}{(logical). Remove distinct unique reads with high
coverage. Likely paralogs or Transposable elements.
Default: \code{remove.unique.reads = TRUE}.}

\item{write.blacklist}{(logical). Write the blacklisted reads to a file.
Default: \code{write.blacklist = TRUE}.}

\item{write.blacklist.fasta}{(logical). Write the blacklisted reads to a
fasta file.
Default: \code{write.blacklist.fasta = TRUE}.}

\item{compress}{(logical) To compress the output files. If you have the disk
space, don't compress, it's way faster this way to write.
Default: \code{compress = FALSE}.}

\item{output}{(character, path) Write the cleaned fq files in a specific directory.
Default: \code{output = "08_stacks_results/03_cleaned_fq"}.}

\item{parallel.core}{(integer) Enable parallel execution with the number of threads.
Default: \code{parallel.core = parallel::detectCores() - 1}.}
}
\value{
The function returns a cleaned fq file with the name of the sample and
\code{-C} appended to the filename.
}
\description{
This function reads the fastq file of an individual and clean it
by removing:
\itemize{
\item unique reads with high coverage (likely paralogs or TE)
\item distinct reads with low coverage
}
}
\details{
coming soon, just try it in the meantime...
}
\examples{
\dontrun{
require(vroom)

# for one sample
clean.id <- stackr::clean_fq(
  fq.files = "my-sample.fq.gz",
  min.coverage.threshold = 7L,
  max.coverage.threshold = "high.coverage.unique.reads"
  )

# for multiple samples in parallel
# require(progressr) # to get a progress bar

 progressr::with_progress({
   clean <- stackr::clean_fq(
     fq.files = 04_process_radtags,
      min.coverage.threshold = 2L,
      max.coverage.threshold = "high.coverage.unique.reads",
      write.blacklist = TRUE,
      write.blacklist.fasta = TRUE,
      compress = FALSE
 )
 })
}
}
